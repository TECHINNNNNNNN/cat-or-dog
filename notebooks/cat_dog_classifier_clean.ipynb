{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üê±üê∂ Cat vs Dog Image Classifier using CNN\n",
    "\n",
    "## Project Overview\n",
    "This notebook demonstrates the development of a Convolutional Neural Network (CNN) for binary image classification, distinguishing between cats and dogs. The model achieves **88.66% validation accuracy** on the famous Dogs vs Cats dataset from Kaggle.\n",
    "\n",
    "## Key Features\n",
    "- Custom CNN architecture with 4 convolutional blocks\n",
    "- Data augmentation for improved generalization\n",
    "- Feature map visualization to understand what the network learns\n",
    "- Interactive prediction interface\n",
    "\n",
    "## Table of Contents\n",
    "1. [Environment Setup](#1-environment-setup)\n",
    "2. [Data Acquisition](#2-data-acquisition)\n",
    "3. [Exploratory Data Analysis](#3-exploratory-data-analysis)\n",
    "4. [Data Preprocessing](#4-data-preprocessing)\n",
    "5. [Model Architecture](#5-model-architecture)\n",
    "6. [Training](#6-training)\n",
    "7. [Model Evaluation](#7-model-evaluation)\n",
    "8. [Feature Visualization](#8-feature-visualization)\n",
    "9. [Inference](#9-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "First, we'll import all necessary libraries and check our computing resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(f\"Keras version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition\n",
    "We'll download the Dogs vs Cats dataset from Kaggle. This dataset contains 25,000 training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and setup Kaggle API\n",
    "!pip install -q kaggle\n",
    "\n",
    "# For Google Colab users: Upload your kaggle.json\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# Setup Kaggle credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n",
    "!unzip -q dogs-vs-cats-redux-kernels-edition.zip\n",
    "!unzip -q train.zip\n",
    "!unzip -q test.zip\n",
    "\n",
    "print(\"‚úÖ Dataset downloaded and extracted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "Let's explore our dataset to understand its structure and visualize some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "train_dir = '/content/train'\n",
    "test_dir = '/content/test'\n",
    "\n",
    "train_files = os.listdir(train_dir) if os.path.exists(train_dir) else []\n",
    "test_files = os.listdir(test_dir) if os.path.exists(test_dir) else []\n",
    "\n",
    "cat_files = [f for f in train_files if f.startswith('cat.')]\n",
    "dog_files = [f for f in train_files if f.startswith('dog.')]\n",
    "\n",
    "print(\"üìä Dataset Statistics:\")\n",
    "print(f\"Total training images: {len(train_files)}\")\n",
    "print(f\"Total test images: {len(test_files)}\")\n",
    "print(f\"Cat images: {len(cat_files)}\")\n",
    "print(f\"Dog images: {len(dog_files)}\")\n",
    "print(f\"Class balance: {len(cat_files)/len(train_files)*100:.1f}% cats, {len(dog_files)/len(train_files)*100:.1f}% dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "fig.suptitle('Dataset Sample: Cats (top) vs Dogs (bottom)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Display 4 random cats\n",
    "for i in range(4):\n",
    "    if cat_files:\n",
    "        random_cat = random.choice(cat_files)\n",
    "        img = mpimg.imread(os.path.join(train_dir, random_cat))\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f'Cat #{random_cat.split(\".\")[1]}')\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "# Display 4 random dogs\n",
    "for i in range(4):\n",
    "    if dog_files:\n",
    "        random_dog = random.choice(dog_files)\n",
    "        img = mpimg.imread(os.path.join(train_dir, random_dog))\n",
    "        axes[1, i].imshow(img)\n",
    "        axes[1, i].set_title(f'Dog #{random_dog.split(\".\")[1]}')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "We'll organize our data into subdirectories and create data generators with augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "print(\"üîß Model Configuration:\")\n",
    "print(f\"Input image size: {IMG_HEIGHT}x{IMG_WIDTH}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Training epochs: {EPOCHS}\")\n",
    "print(f\"Validation split: {VALIDATION_SPLIT*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize images into class subdirectories\n",
    "def organize_dataset(base_dir):\n",
    "    \"\"\"Organize images into cats/ and dogs/ subdirectories.\"\"\"\n",
    "    cats_dir = os.path.join(base_dir, 'cats')\n",
    "    dogs_dir = os.path.join(base_dir, 'dogs')\n",
    "    \n",
    "    os.makedirs(cats_dir, exist_ok=True)\n",
    "    os.makedirs(dogs_dir, exist_ok=True)\n",
    "    \n",
    "    files = [f for f in os.listdir(base_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    cats_moved = dogs_moved = 0\n",
    "    \n",
    "    for filename in files:\n",
    "        if filename.startswith('cat.'):\n",
    "            shutil.move(os.path.join(base_dir, filename), \n",
    "                       os.path.join(cats_dir, filename))\n",
    "            cats_moved += 1\n",
    "        elif filename.startswith('dog.'):\n",
    "            shutil.move(os.path.join(base_dir, filename), \n",
    "                       os.path.join(dogs_dir, filename))\n",
    "            dogs_moved += 1\n",
    "    \n",
    "    return cats_moved, dogs_moved\n",
    "\n",
    "# Only organize if not already done\n",
    "if not os.path.exists('/content/train/cats'):\n",
    "    cats_moved, dogs_moved = organize_dataset('/content/train')\n",
    "    print(f\"‚úÖ Organized {cats_moved} cat images and {dogs_moved} dog images\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset already organized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/content/train',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/content/train',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Generator Summary:\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Class mapping: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Architecture\n",
    "We'll build a custom CNN with 4 convolutional blocks followed by dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape=(150, 150, 3)):\n",
    "    \"\"\"\n",
    "    Create a CNN model for binary classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - 4 Convolutional blocks (Conv2D + MaxPooling2D)\n",
    "    - Dropout for regularization\n",
    "    - Dense layers for classification\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        \n",
    "        # Block 1: 32 filters\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', name='conv1'),\n",
    "        layers.MaxPooling2D(2, 2, name='pool1'),\n",
    "        \n",
    "        # Block 2: 64 filters\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', name='conv2'),\n",
    "        layers.MaxPooling2D(2, 2, name='pool2'),\n",
    "        \n",
    "        # Block 3: 128 filters\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', name='conv3'),\n",
    "        layers.MaxPooling2D(2, 2, name='pool3'),\n",
    "        \n",
    "        # Block 4: 128 filters\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', name='conv4'),\n",
    "        layers.MaxPooling2D(2, 2, name='pool4'),\n",
    "        \n",
    "        # Classification head\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation='relu', name='dense1'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile model\n",
    "model = create_cnn_model()\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training\n",
    "Train the model with our augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üöÄ Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")\n",
    "print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "Visualize training history and save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation accuracy/loss.\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "    ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and training history\n",
    "# For Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# model.save('/content/drive/MyDrive/cat_dog_cnn_model.h5')\n",
    "\n",
    "# For local environment\n",
    "model.save('cat_dog_cnn_model.h5')\n",
    "print(\"‚úÖ Model saved successfully!\")\n",
    "\n",
    "# Save training history\n",
    "with open('training_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"‚úÖ Training history saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Visualization\n",
    "Visualize what the CNN learns at different layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, img_path, num_layers=8):\n",
    "    \"\"\"\n",
    "    Visualize feature maps from CNN layers.\n",
    "    Shows what patterns the network detects at different depths.\n",
    "    \"\"\"\n",
    "    # Create a model that outputs intermediate layer activations\n",
    "    layer_outputs = [layer.output for layer in model.layers[:num_layers]]\n",
    "    activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Preprocess image\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    # Get activations\n",
    "    activations = activation_model.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Plot\n",
    "    layer_names = ['Conv1', 'Pool1', 'Conv2', 'Pool2', \n",
    "                   'Conv3', 'Pool3', 'Conv4', 'Pool4']\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    # Show original\n",
    "    plt.subplot(2, 5, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Original Image', fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show feature maps\n",
    "    for i, (activation, name) in enumerate(zip(activations[:8], layer_names)):\n",
    "        plt.subplot(2, 5, i+2)\n",
    "        # Display first channel of the activation\n",
    "        plt.imshow(activation[0, :, :, 0], cmap='viridis')\n",
    "        plt.title(f'{name}\\n{activation.shape[1:3]}', fontsize=10)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle('CNN Feature Maps Visualization', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (requires an image path)\n",
    "# visualize_feature_maps(model, 'path/to/image.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inference\n",
    "Functions for making predictions on new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, img_path, show_plot=True):\n",
    "    \"\"\"\n",
    "    Predict whether an image contains a cat or dog.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained Keras model\n",
    "        img_path: Path to image file\n",
    "        show_plot: Whether to display the image with prediction\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results with class and confidence\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array, verbose=0)\n",
    "    probability = prediction[0][0]\n",
    "    \n",
    "    # Determine class\n",
    "    if probability > 0.5:\n",
    "        predicted_class = 'Dog'\n",
    "        confidence = probability\n",
    "    else:\n",
    "        predicted_class = 'Cat'\n",
    "        confidence = 1 - probability\n",
    "    \n",
    "    # Display result\n",
    "    if show_plot:\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Prediction: {predicted_class}\\nConfidence: {confidence:.2%}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'class': predicted_class,\n",
    "        'confidence': confidence,\n",
    "        'raw_probability': probability\n",
    "    }\n",
    "\n",
    "# Test the model\n",
    "print(\"üéØ Model ready for predictions!\")\n",
    "print(\"Use: predict_image(model, 'path/to/your/image.jpg')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Model Performance\n",
    "- **Training Accuracy**: ~87%\n",
    "- **Validation Accuracy**: ~89%\n",
    "- **Architecture**: 4-block CNN with 3.45M parameters\n",
    "- **Training Time**: ~33 minutes on GPU\n",
    "\n",
    "### Key Techniques Used\n",
    "1. **Data Augmentation**: Rotation, shifting, flipping, and zooming to prevent overfitting\n",
    "2. **Dropout Regularization**: 50% dropout before final dense layer\n",
    "3. **Progressive Feature Extraction**: Increasing filter sizes (32‚Üí64‚Üí128‚Üí128)\n",
    "4. **Binary Cross-Entropy Loss**: Optimal for two-class classification\n",
    "\n",
    "### Next Steps\n",
    "- Deploy model using Streamlit for web interface\n",
    "- Experiment with transfer learning (VGG16, ResNet50)\n",
    "- Implement Grad-CAM for better interpretability\n",
    "- Add model versioning and experiment tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}