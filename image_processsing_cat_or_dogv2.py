# -*- coding: utf-8 -*-
"""Image processsing cat or dogv2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Llh1HLPqKWXwP4QcETUEKTjxQoLzYe-n
"""

# First, let's import our essential libraries
import tensorflow as tf
from tensorflow import keras
import numpy as np
import matplotlib.pyplot as plt
import os

# Check if we have GPU access (fingers crossed!)
print("TensorFlow version:", tf.__version__)
print("GPU Available: ", tf.config.list_physical_devices('GPU'))

# Install Kaggle API
!pip install kaggle

# Upload your kaggle.json file
from google.colab import files
uploaded = files.upload()

!mkdir -p ~/.kaggle
!cp 'kaggle.json' ~/.kaggle/kaggle.json
!chmod 600 ~/.kaggle/kaggle.json

!kaggle competitions list

# The famous dataset
!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition
!unzip -q dogs-vs-cats-redux-kernels-edition.zip

!ls -la

# Check what's inside
!ls -la train/
!ls -la test/

# Count how many images we have
!echo "Training images:"
!ls train/ | wc -l

!echo "Test images:"
!ls test/ | wc -l

# Look at a few filenames to understand the naming pattern
!ls train/ | head -10

# Unzip the training data
!unzip -q train.zip

# Unzip the test data
!unzip -q test.zip

# Now let's see what we got
!ls -la

# Check the structure
!ls -la train/ | head -10
!ls -la test/ | head -10

# Count the images
!echo "Training images:"
!ls train/ | wc -l

!echo "Test images:"
!ls test/ | wc -l

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os

train_dir = '/content/train'

cat_files = [f for f in os.listdir(train_dir) if f.startswith('cat.')]
dog_files = [f for f in os.listdir(train_dir) if f.startswith('dog.')]

print(f"Total cats: {len(cat_files)}")
print(f"Total dogs: {len(dog_files)}")

fig, axes = plt.subplots(2, 4, figsize=(15, 8))
fig.suptitle('Our Cat vs Dog Dataset - Random Samples', fontsize=16)


# Show 4 random cats
for i in range(4):
    random_cat = random.choice(cat_files)
    img = mpimg.imread(os.path.join(train_dir, random_cat))
    axes[0, i].imshow(img)
    axes[0, i].set_title(f'Cat: {random_cat}')
    axes[0, i].axis('off')

# Show 4 random dogs
for i in range(4):
    random_dog = random.choice(dog_files)
    img = mpimg.imread(os.path.join(train_dir, random_dog))
    axes[1, i].imshow(img)
    axes[1, i].set_title(f'Dog: {random_dog}')
    axes[1, i].axis('off')


plt.tight_layout()
plt.show()

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

# Let's set some key parameters
IMG_HEIGHT = 150  # Resize all images to 150x150 (good balance of detail vs speed)
IMG_WIDTH = 150
BATCH_SIZE = 32   # Process 32 images at a time
EPOCHS = 15       # How many times to go through the entire dataset

print(f"Target image size: {IMG_HEIGHT}x{IMG_WIDTH}")
print(f"Batch size: {BATCH_SIZE}")

train_datagen = ImageDataGenerator(
    rescale=1./255,         # Normalize pixel values to 0-1
    rotation_range=20,      # Randomly rotate images
    width_shift_range=0.2,  # Randomly shift images horizontally
    height_shift_range=0.2, # Randomly shift images vertically
    horizontal_flip=True,   # Randomly flip images horizontally
    zoom_range=0.2,        # Randomly zoom in/out
    validation_split=0.2   # Use 20% of data for validation
)

validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2 )

import os
import shutil

os.makedirs('/content/train/cats', exist_ok=True)
os.makedirs('/content/train/dogs', exist_ok=True)

train_files = os.listdir('/content/train')

cats_moved = 0
dogs_moved = 0

for filename in train_files:
    if filename.startswith('cat.') and filename.endswith('.jpg'):
        shutil.move(f'/content/train/{filename}', f'/content/train/cats/{filename}')
        cats_moved += 1
    elif filename.startswith('dog.') and filename.endswith('.jpg'):
        shutil.move(f'/content/train/{filename}', f'/content/train/dogs/{filename}')
        dogs_moved += 1

print(f"Moved {cats_moved} cat images")
print(f"Moved {dogs_moved} dog images")

train_generator = train_datagen.flow_from_directory(
    '/content/train',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='training'     # Use 80% for training
)

validation_generator = validation_datagen.flow_from_directory(
    '/content/train',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode='binary',
    subset='validation'   # Use 20% for validation
)

print(f"Training samples: {train_generator.samples}")
print(f"Validation samples: {validation_generator.samples}")
print(f"Classes: {train_generator.class_indices}")

# Let's start building our model
from tensorflow.keras import Input

model = models.Sequential([
    # Explicit Input Layer
    Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    # Layer 1: First Convolutional Block
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    # Layer 2: Second Convolutional Block
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    # Layer 3: Third Convolutional Block
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    # Layer 4: Fourth Convolutional Block
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(2, 2),

    # Flatten and Dense layers
    layers.Flatten(),
    layers.Dropout(0.5),
    layers.Dense(512, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Binary classification: 0=cat, 1=dog
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

history = model.fit(
    train_generator,
    validation_data=validation_generator,
    epochs=EPOCHS,
    verbose=1
)

from google.colab import drive
drive.mount('/content/drive')

model.save('/content/drive/MyDrive/cat_dog_cnn_model.h5')
print("‚úÖ Model saved successfully to Google Drive!")

model.save_weights('/content/drive/MyDrive/cat_dog_.weights.h5')
print("‚úÖ Model weights saved successfully!")

import pickle
with open('/content/drive/MyDrive/training_history.pkl', 'wb') as f:
    pickle.dump(history.history, f)

import numpy as np
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt


def predict_cat_or_dog(img_path):
  img = image.load_img(img_path, target_size=(150, 150))
  img_array = image.img_to_array(img)
  img_array = np.expand_dims(img_array, axis=0)
  img_array /= 255.0

  prediction = model.predict(img_array)
  probability = prediction[0][0]

  plt.imshow(img)
  plt.axis('off')

  if probability > 0.5:
    plt.title(f"Prediction: Dog (Probability: {probability:.2f})")
  else:
    plt.title(f"Prediction: Cat (Probability: {1 - probability:.2f})")

  plt.show()
  return probability

from google.colab import files
uploaded = files.upload()

for filename in uploaded.keys():
  print(f"Testing {filename}")
  predict_cat_or_dog(filename)

import matplotlib.pyplot as plt
import numpy as np
from tensorflow.keras import Model
from tensorflow.keras.preprocessing import image

# Create the visualization model using the working input
layer_outputs = [layer.output for layer in model.layers[:8]]
activation_model = Model(inputs=model.layers[0].input, outputs=layer_outputs)

def visualize_feature_maps(img_path):
    # Preprocess image
    img = image.load_img(img_path, target_size=(150, 150))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    # Get activations
    activations = activation_model.predict(img_array)

    plt.figure(figsize=(20, 10))

    # Show original
    plt.subplot(2, 5, 1)
    plt.imshow(img)
    plt.title('üê∂ Original Image')
    plt.axis('off')

    # Layer names
    layer_names = ['Conv2D_1 (32)', 'MaxPool_1', 'Conv2D_2 (64)', 'MaxPool_2',
                   'Conv2D_3 (128)', 'MaxPool_3', 'Conv2D_4 (128)', 'MaxPool_4']

    # Show feature maps
    for i, (activation, name) in enumerate(zip(activations, layer_names)):
        if i < 8:  # Show first 8
            plt.subplot(2, 5, i+2)
            plt.imshow(activation[0, :, :, 0], cmap='viridis')
            plt.title(f'{name}\n{activation.shape[1:]}')
            plt.axis('off')

    plt.tight_layout()
    plt.show()

    print("Feature map shapes:")
    for name, activation in zip(layer_names, activations):
        print(f"{name}: {activation.shape}")

from google.colab import files
uploaded = files.upload()

for filename in uploaded.keys():
  print(f"Testing {filename}")
  visualize_feature_maps(filename)

# Try it!

# Let's see multiple channels from Conv2D_2 (where you saw patterns!)
def show_multiple_channels(img_path, layer_index=2, num_channels=8):
    img = image.load_img(img_path, target_size=(150, 150))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0

    activations = activation_model.predict(img_array)
    target_activation = activations[layer_index]  # Conv2D_2

    plt.figure(figsize=(16, 8))
    plt.suptitle(f'Conv2D_2: First {num_channels} Feature Maps', fontsize=16)

    for i in range(num_channels):
        plt.subplot(2, 4, i+1)
        plt.imshow(target_activation[0, :, :, i], cmap='viridis')
        plt.title(f'Channel {i}')
        plt.axis('off')

    plt.tight_layout()
    plt.show()

for filename in uploaded.keys():
  print(f"Testing {filename}")
  show_multiple_channels(filename)

from google.colab import drive
drive.mount('/content/drive')

from tensorflow.keras.models import load_model
model = load_model('/content/drive/MyDrive/cat_dog_cnn_model.h5')
print("‚úÖ Model loaded successfully!")

import numpy as np
test_input = np.random.random((1, 150, 150, 3))
test_pred = model.predict(test_input)
print(f"‚úÖ Model working! Test prediction: {test_pred[0][0]:.3f}")